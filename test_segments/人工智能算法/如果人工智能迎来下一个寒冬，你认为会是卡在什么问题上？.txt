以前天天跟导师探讨AI的未来发展之路，我就来写两笔。我目前来看，最急需要解决的问题如下：

1.RL的样本复杂度问题。从13年的Atari，到16年的AlphaGo，到今年的Dota 5v5和星际争霸，每个游戏都经历了N多个（可能如果复原到人类时间是几百年+）样本，才可以学到一个好的policy。如果通用智能出来，那么一定不是在游戏里，而是在现实世界中。现实世界中没有办法给你这么多次尝试的机会 -- 生命诚可贵，人只活一次。不管是imitation learning，meta learning还是最近OpenAI出的ADR，距离解决这个问题都还是有距离。甚至我们可能要挑战增强学习RL这个学习框架本身。
2.受Yann的影响太深 -- 无监督学习。我是比较相信人们可以从观看世界中学到东西的。但是怎么学，学到的是什么，如何eval，目前我们甚至都没有定义清楚无监督学习到底是什么（我的博士毕业论文就写的这个主题，真是惭愧得很）。宏观上是这样，微观上更是，我做GAN的时候15年开始，如今快20年了，我依然没有看到一个满意的权衡图片生成质量的方法（堆人来看都行啊！You're welcome, Amazon）。再说大一点，GAN给我们带来一种approximate 数据分布的生成机制，我们如何将这个问题formulate到无监督学习里面？
3.层级化学习。“我要去楼下吃一碗拉面”。这个问题是个RL问题吗？当然可以这么做，你成功走到了面馆，我给你个reward，否则没有。但实际上不是这样的，这里的policy有非常结构化的层级性。第一个分解动作是，我要先走出我的屋子，然后走到电梯，下楼，出楼，之后走到面馆。那么每个动作都可以再细： 比如说我怎么走出屋子？我首先是两脚蹬地，起身，站直，收臀，然后转身，走向门。我们有这样的问题定义吗？
4.图像分类问题需要被重新评估A. 当你看到一个东西是苹果的时候，你是如何做的判断？你不是某个角度（不管是2D还是3D）来一张图，之后就能判断了。你的判断方式是，你走过去，四周看一看，甚至摸一摸，然后做出一个判断。大家都说多模态多模态，我们现在CV依然没有走出单模态的阴影。
5.图像分类问题需要被重新评估B. 你看到一个桌子，它确实是个桌子，这没错。但是我要是坐上去呢？你的分类应该把它当成一个椅子，而不是桌子。我们的图像分类算法如果被看成policy的话，这个policy的state太单一了（就是一张图），但是其实它的state需要被更加丰富化才可以。可控制的文本生成。大家都觉得好热闹啊这一年多，ELMO, BERT, XLNET, GPT-2, Roberta, T5等等。GPT-2可以做的文本生成太厉害了，那句子真实到爆。但是，你怎么控制它呢？比如说我想生成个新闻稿，我要求每个字每句话都跟主题息息相关，责任编辑的名字不能瞎闹，这个问题到今天都没有解决方案哦。说到底，我们不知道一个RNN语言模型是怎么工作的，尤其是有condition的时候，什么时候是根据语言本身的流利度生成(unconditional)  什么时候是根据condition来生成，目前我们没办法开发一个合适gating方式来区分。NLG想真正落地，这个问题不解决的话，没有一点希望（Forgive me创业者们）。
6.符号主义？Gary Marcus一直在死咬着这个点。我的观点目前比较中立：我们或许应该融合符号主义，而不是完全ditch掉它。最简单的，我很欣喜可以看到有些工作是真正得把知识图谱或者语法信息用到NLP问题上面了，而且效果确实有些提升。但同时，我们真的需要知识图谱吗？BERT训练的方式能不能作为一个知识图谱。同学们，掏出你的BERT模型，输入一句 The CEO of Baidu is <mask>。看看它给你返回什么？我的意思是：三元组，四元组这样的简单知识图谱的定义已经不适用了。混了工业界一段时间，我看到的真实世界中的数据维度太太太太太多了，三或者四都远远不足，我们要的是个Variable-number元祖。或许BERT给出了一条新路。

最后，大家请加油吧。AI的研究上面真的有太多痛点问题需要被解决。上面任何一个问题解决我都认为是伟大的，都会避免下一个寒冬。请不要再死死盯住一个benchmark不放去刷分了呀年轻人们！要么落地一个场景，要么解决一个问题。Research最有趣的就是把一个问题从头到尾定义得明明白白，颇见功力。

也推荐下我的知识星球吧，时不时会写点干货~ (这个是我： https://cs.nyu.edu/~jakezhao/research.html）
<img src="https://pica.zhimg.com/50/v2-60c0705b5feef21f59ef50a3d4ff2706_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="690" data-rawheight="930" data-default-watermark-src="https://pic3.zhimg.com/50/v2-dc1a73a5244820b4b69e211bf8d2a411_720w.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="690" data-original="https://pic2.zhimg.com/v2-60c0705b5feef21f59ef50a3d4ff2706_r.jpg?source=1940ef5c"/>
