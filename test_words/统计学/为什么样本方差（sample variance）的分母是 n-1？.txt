[ 非常 好 的 问题 ， 探索 这个 问题 的 答案 ， 不仅 能 更好 的 了解 自己 和 这个 世界 ， 还 能 避免 被 征收 “ 偏差 税 ” Bias   Tax ！ ,   " 先说 结论 ， 样本 标准差 的 分母 写成 n - 1 ， 是 为了 对 自由度 进行 校正 ， 这 叫 贝塞尔 校正 （ Bessels   Correction ） [ 1 ] 。 注意 这个 贝塞尔 不是 贝塞尔 曲线 （ B é zier   curve ） 那个 贝塞尔 。 " ,   为了 让 中学 水平 的 读者 就 能 理解 ， 我 尽量 不用 公式 ， 用 浅显 的 语言 和 生活 中 的 案例 ， 来 叙述 这个 问题 的 来龙去脉 。 这 算是 对 其他 答案 的 补充 ， 也许 看 完后 ， 再 看 其他 高手 的 回答 就 没 那么 难 了 。 ,   在 统计 领域 ， 你 经常 会 看到 ， 为了 减少 干扰 数据 对 结论 的 影响 ， 数学家 设计 了 大量 的 技术手段 来 对 数据 进行 校正 。 ,   先看 一篇 我 改编 的 故事 《 比尔盖茨 冲 进 酒吧 》 ： ,   一天 晚上 ， 小镇 酒吧 里 坐 着 9 个人 ， 大家 都 是 小镇 上 的 工薪族 ， 年薪 的 平均值 在 5 万美元 左右 。 ,   < img   src = " https : / / pic1 . zhimg . com / 50 / v2 - b43c8fd8e8fbae307442d58a81b5032b _ 720w . jpg ? source = 1940ef5c "   data - caption = " "   data - size = " normal "   data - rawwidth = " 1298 "   data - rawheight = " 470 "   data - default - watermark - src = " https : / / pica . zhimg . com / 50 / v2 - de33092e8714f0b92185d2a01651b9d3 _ 720w . jpg ? source = 1940ef5c "   class = " origin _ image   zh - lightbox - thumb "   width = " 1298 "   data - original = " https : / / pic3 . zhimg . com / v2 - b43c8fd8e8fbae307442d58a81b5032b _ r . jpg ? source = 1940ef5c " / > ,   从 上面 的 数据 和 图表 ， 你 可以 看出 50000 美元 这个 平均值 ， 比较 准确 的 体现 了 9 个人 的 收入水平 。 ,   正在 此时 ， 比尔盖茨 急匆匆 的 走进 酒吧 ， 冲向 厕所 … … ,   假如 比尔盖茨 的 年薪 是 10 亿美元 ， 在 他 上 厕所 的 时间 里 ， 另外 9 个人 啥 也 没 做 ， 加上 比尔盖茨 ， 10 个人 的 平均 年薪 平均值 一下子 从 5 万 爆涨 到 1 亿美元 。 ,   < img   src = " https : / / pica . zhimg . com / 50 / v2 - 2caa10c42416196d000ecf8cc9ceebad _ 720w . jpg ? source = 1940ef5c "   data - caption = " "   data - size = " normal "   data - rawwidth = " 1330 "   data - rawheight = " 1415 "   data - default - watermark - src = " https : / / pic1 . zhimg . com / 50 / v2 - ca331be99ee1e59c71d75285a4ffc7b6 _ 720w . jpg ? source = 1940ef5c "   class = " origin _ image   zh - lightbox - thumb "   width = " 1330 "   data - original = " https : / / pic1 . zhimg . com / v2 - 2caa10c42416196d000ecf8cc9ceebad _ r . jpg ? source = 1940ef5c " / > ,   如图 ， 相比之下 ， 和 比尔盖茨 相比 ， 9 人 的 年薪 太渣 ， 完全 看不出 高度 ， 像 二向箔 一样 薄 。 ,   而 当 比尔盖茨 离开 后 ， 他们 还是 啥 也 没 做 ， 平均 年薪 却 暴跌 了 近 1 亿美元 。 ,   9 人 抱头 哭 死 在 厕所 … … ,   剧终 ^ _ ^ ,   ,   在 这个 例子 里 ， 比尔盖茨 就是 一个 干扰 数据 ， 因为 他 的 存在 ， 让 平均值 的 计算 并 不能 体现 酒吧 里 工薪族 的 真实 平均水平 ， 9 人 的 平均 年薪 无缘无故 的 涨 到 了 1 亿 。 当然 这个 数 也 无法 体现 比尔盖茨 的 真实 收入水平 ， 因为 他 缩水 到 了 1 亿 。 ,   那 统计学家 应该 怎么办 呢 ？ ,   在 统计 上 ， 把 比尔盖茨 这种 干扰 数据 称为 异常 值 （ Outlier ） 。 ,   应对 这种 异常 值 ， 最 简单 的 方法 就是 排除 掉 它们 。 在 计算 平均值 时 把 比尔盖茨 排除 掉 ， 就 无法 干扰 平均值 了 。 （ 当然 实际 应用 比较复杂 ， 排除 异常 值 需要 谨慎 ， 不能 随意 的 排除 ） ,   ,   排除法 这种 技术手段 也 经常 应用 在 比赛 打分 上 。 ,   我们 知道 裁判 打分 的 主观性 非常 大 ， 为了 减少 单个 教练 的 影响 ， 比赛 通常 会 安排 多个 裁判 一起 给 选手 打分 ， 然后 再取 一个 平均值 。 ,   但 实际上 在 求 平均值 时 ， 还会 再 去掉 最高分 和 最低 分 ， 然后 对 剩下 的 分数 计算 平均值 。 ,   这种 排除 最高 / 低分 的 手段 也 是 为了 消除 干扰 ， 因为 最高分 和 最低 分 对 平均值 的 影响 比较 大 ， 会 大幅 偏离 真实 的 水平 。 ,   例如 ， 下面 是 10 个 裁判 的 打分 ,   < img   src = " https : / / pica . zhimg . com / 50 / v2 - 617061ebeb1f13233a224eddc45e41b3 _ 720w . jpg ? source = 1940ef5c "   data - caption = " "   data - size = " normal "   data - rawwidth = " 1303 "   data - rawheight = " 729 "   data - default - watermark - src = " https : / / pic2 . zhimg . com / 50 / v2 - d2eb28b10b22df3e0640030c2ad12b17 _ 720w . jpg ? source = 1940ef5c "   class = " origin _ image   zh - lightbox - thumb "   width = " 1303 "   data - original = " https : / / pic3 . zhimg . com / v2 - 617061ebeb1f13233a224eddc45e41b3 _ r . jpg ? source = 1940ef5c " / > ,   上图 中 最高分 把 选手 的 平均值 拉高 了 0.60 分 ， 你 可能 会 说 ， 这点 分数 不算 啥 ， 应该 影响 不 大 。 ,   但 在 实际 的 比赛 中 ， 选手 的 差距 通常 非常 的 小 ， 0.1 分都会 对 选手 的 排名 产生 显著 的 影响 。 ,   为了 尽可能 消除 其 干扰 ， 得到 一个 相对 客观 的 平均值 ， 通常 在 计算 平均值 时 ， 会 排除 掉 最低 分 和 最高分 ， 这样 算 出来 的 平均值 叫 裁剪 平均值 （ Truncated   mean ） 。 ,   ,   比尔盖茨 和 去掉 最高 / 低分 的 这 两个 例子 ， 都 是 为了 说明 统计 领域 的 校正 技术 ， 用 排除法 来 消除 掉 干扰 数据 的 影响 。 ,   ,   现在 你 也 可能 意识 到 了 ， 在 样本 方差 的 计算 上 ， 分母 使用 （ n - 1 ） ， 而 不是 n ， 也 是 一种 排除法 来 消除 干扰 的 技术手段 。 ,   ,   为什么 要 减去 1 ， 这个 1 代表 的 是 哪个 数 ？ ,   这个 减去 的 1 ， 不 特指 任何 一个 数 ， 1 代表 那个 失去 “ 独立 客观 ” 的 维度 （ 自由度 ） 。 ,   看 不 明白 ？ ,   正常 ， 听 我 慢慢 解释 。 ,   ,   在 我们 在 对 全体 进行 采样 时 ， 有 一个 至关重要 的 前提条件 ， 就是 一定 要 随机 采样 ， 这 其中 的 关键词 是 随机 。 ,   之所以 要 随机 ， 这是 为了 避免出现 样本偏差 。 因为 如果 样本 错 了 ， 后面 的 计算 步骤 即使 全部 都 正确 ， 最终 结果 也 是 错 的 。 ,   例如 ， 要 想 回答 “ 中国 人 是不是 喜欢 吃 狗肉 ？ ” 的 问题 。 ,   < img   src = " https : / / pica . zhimg . com / 50 / v2 - b5e102aa9f948085680119af7a20e625 _ 720w . jpg ? source = 1940ef5c "   data - caption = " "   data - size = " normal "   data - rawwidth = " 500 "   data - rawheight = " 493 "   data - default - watermark - src = " https : / / pica . zhimg . com / 50 / v2 - 560ee676f9672c165d96569e3b7fdc66 _ 720w . jpg ? source = 1940ef5c "   class = " origin _ image   zh - lightbox - thumb "   width = " 500 "   data - original = " https : / / pic2 . zhimg . com / v2 - b5e102aa9f948085680119af7a20e625 _ r . jpg ? source = 1940ef5c " / > ,   请问 ， 以下 两个 采样 ， 哪 一个 能 得到 客观 的 结论 ？ ,   只 去 玉林 狗肉 节上 采样 。 对 中国 人 进行 时间 和 地点 都 随机 的 采样 。 ,   两种 采样 方法 ， 会 得出 截然 相反 的 结论 。 ,   前 一种 采样 很 不 自由 ， 被 限制 在 一个 极其 有限 的 时空 里 。 后 一种 采样 有 充分 的 自由 ， 跳出 限制 ， 可以 没有 干扰 的 随机 采样 。 ,   如果 只 在 玉林 采样 ， 这个 样本 就是 偏差 样本 （ Biased   Sample ） ， 是 不具 代表性 的 样本 （ Unrepresentative   Sample ） 。 ,   如果 根据 这个 偏差 样本 ， 得出 了 “ 中国 人 居然 吃 狗肉 ， 太 野蛮 了 ！ ” 的 结论 。 无论 在 逻辑 上 如何 完美 ， 最终 结论 也 是 荒谬 的 。 ,   这 就是 所谓 的 “ 垃圾 进 ， 垃圾 出 ” （ Garbage   in   ，   garbage   out ） [ 2 ] ,   ,   你 在 玉林 采样 越 多 ， 你 的 偏见 就 会 越深 ， 只会 进一步 的 固化 你 的 偏见 。 ,   但 自由 的 随机 采样 ， 你 采样 越 多 ， 你 的 偏见 就 会 越来越少 ， 看到 更 真实 、 更 多样化 的 中国 人 。 ,   ,   在 这里 需要 暂停 一下 ： ,   请 大家 反思 一下 ， 自己 是不是 也 曾 犯过 同样 的 错误 ， 取错 了 样本 ， 出现 了 偏差 或 偏见 （ Bias ） ？ ,   反正 ， 我 经常 会犯 这样 的 错误 ， 轻易 就 相信 传言 [ 3 ] ， 或 轻易 给 别人 扣 上 帽子 [ 4 ] ， 这 都 是 偏见 。 ,   （ 罪过 ， 罪过 ， 宽恕 我 吧 ， 我 知道 自己 错 了 ！ ） ,   ,   我们 普通人 经常 会 因为 样本偏差 ， 被 收取 “ 偏差 税 ” ( Bias   Tax ) ,   例如 彩票 ， 就是 利用 了 人们 的 这 一 弱点 。 ,   彩民 们 只 注意 到 了 那些 极少数 获得 大奖 的 人 ， 看不到 绝大 数 人 赔钱 。 ,   越是 盯 着 那些 获奖 的 人 看 ， 彩民 们 的 偏见 越深 ， 越是 坚信 自己 会 中奖 。 ,   他们 因为 在 选取 样本 时 出现 偏差 ， 而 被 别人 收税 。 ,   好 吧 ， 我 承认 ， 偏差 税 这个 词是 我 根据 智商 税 这个 词 编造 出来 的 ( ^ _- ) 。 ,   很多 人 喜欢 用 智商 税 这个 词来 嘲笑 犯错 的 人 智商 低 ， 但 智商 税 这个 词是 有 偏差 的 。 ,   因为 不能 根据 一个 事件 就 推算出 一个 人 整体 的 智商 ， 这是 不具 代表性 的 有 偏 样本 ， 这是 偏见 。 ,   例如 很多 彩民 的 智商 很 高 ， 他们 使用 各种 复杂 的 公式 ， 做 了 大量 复杂 的 计算 ， 他们 的 智商 一点 都 不 低 ， 他们 的 问题 是 出 在 样本偏差 上 。 ,   而 偏差 税 这个 词 和 智商 税 不 一样 ， 不论 我们 的 智商 高低 ， 人人 都 会 有 偏见 ， 事事 都 会 出 偏差 ， 这个 税 每个 人 都 在 交 。 ,   例如 ， 股票市场 上 的 散户 ， 迷信 中医 和 保健品 的 大爷 大妈 ， 轻信 谣言 的 吃 瓜 群众 ， … … ， 几乎 无人 可以 幸免 ， 都 在 为 样本偏差 付出代价 。 ,   推荐 一个 TED 演讲 《 为什么 应该 热衷于 统计学 》 。 ,   看 完 就 知道 人们 对 这个 世界 的 偏差 有 多 大 了 。 ,   所以 人们 不是 智商 出 了 问题 ， 是 在 选取 样本 时 出现 了 偏差 ， 所以 偏差 税是 一个 更 客观 （ 无偏 ） 的 词 。 ,   ,   其实 ， 不仅 是 普罗 大众 ， 就是 那些 权倾 一时 的 政治家 ， 也 曾 为 样本偏差 付出 过 惨重 的 代价 。 ,   1948 年 美国 大选 ， 大部分 报纸 都 预测 杜威 会 战胜 杜鲁门 ， 当选 美国 总统 。 社会舆论 一致 看好 杜威 ， 以至于 竞选 当天 ， 杜威 认为 杜鲁门 很快 就 会 打电话 庆祝 他 当选 。 ,   但 竞选 结果 却 大跌眼镜 ， 最终 是 杜鲁门 当选 。 （ 是不是 有些 似曾相识 ？ ） ,   < img   src = " https : / / pic1 . zhimg . com / 50 / v2 - 47a3c80f67b50207b76cfb87a72e8c9a _ 720w . jpg ? source = 1940ef5c "   data - size = " normal "   data - rawwidth = " 1280 "   data - rawheight = " 720 "   data - default - watermark - src = " https : / / pic2 . zhimg . com / 50 / v2 - ef8759ff011c83f7bbfc17faee0a1ec3 _ 720w . jpg ? source = 1940ef5c "   class = " origin _ image   zh - lightbox - thumb "   width = " 1280 "   data - original = " https : / / pic1 . zhimg . com / v2 - 47a3c80f67b50207b76cfb87a72e8c9a _ r . jpg ? source = 1940ef5c " / > 杜鲁门 获胜 后 ， 兴高采烈 的 举着 那些 提前 预测 杜威 击败 杜鲁门 的 报纸 ， 笑 得 好 真诚 啊 ！ ,   图片 来源 ： https : / / www . youtube . com / watch ? v = h4uUV1klrkM ,   这次 的 预测 之所以 会 失败 ， 是因为 调查 机构 通过 电话 调查 的 方式 做 的 采样 。 ,   1948 年 ， 虽然 电话 已 发明 多年 ， 但 价格 并 不 便宜 ， 有 电话 的 多 是 相对 富裕 的 家庭 ， 多数 人 的 家里 没有 普及 电话 。 也就是说 ， 这种 采样 是 有 偏差 的 ， 只 反映 了 富裕 阶层 的 观点 ， 无法 反映 当时 主流 选民 的 意愿 ， 也 就是 统计 出现 了 样本偏差 。 [ 5 ] ,   在 当时 ， 除了 很多 美国 人 被 误导 ， 还有 一个 人 也 因为 这个 样本偏差 ， 把 所有 筹码 错压 在 了 杜威 的 身上 ， 结果 却 因此 而 丢掉 了 整个 江山 ， 此人 就是 蒋介石 。 本来 杜鲁门 在 做 副 总统 时 就 对 蒋介石 印象 很差 ， 在 他 当选 后 ， 更是 变本加厉 ， 很快 减少 了 对 蒋介石 的 援助 。 [ 6 ] ,   常凯申 也 哭 死 在 厕所 ！ ,   ,   事实上 ， 有太多 的 仇恨 、 歧视 、 偏见 和 武断 的 观点 ， 是 建立 在 样本偏差 的 垃圾 数据 之上 的 。 ,   因为 “ 垃圾 进 ， 垃圾 出 ” ， 无论 人们 如何 雄辩 ， 逻辑 上 如何 完美 ， 算法 上 如何 先进 ， 结论 也 是 一堆 错误 的 垃圾 。 [ 7 ] ,   这是 值得 你 、 我 、 以及 所有人 都 应该 警惕 的 现象 。 ,   例如 ： 你 想 知道 当代 日本 人 是 怎样 的 。 就 不能 只 对 抗日 神剧 进行 采样 ， 不能 只 对 日本 右翼 进行 采样 ， 要 获得 真实 的 数据 ， 必须 去 日本 实地 对 日本 人 进行 随机 采样 。 ,   只有 采样 是 随机 ， 是 不带 偏差 的 （ Unbiased ） ， 才能 保证 自己 吃 进去 的 不是 垃圾 信息 ， 这是 得出 正确 结论 的 第一步 。 ,   ,   只要 人人 都 追求 无 偏差 ， 世界 会 变成 美好 的 人间 ,   ,   除了 要 做到 采样 是 随机 的 ， 还要 确保 样本 之间 是 互相 独立 的 ， 在 统计 上用 自由度 （ Degrees   of   freedom ） 来 描述 这种 独立性 。 ,   ,   我们 以 常见 的 招投标 为 案例 ， 解释一下 独立性 。 ,   有个 学校 要盖 教学楼 ， 邀请 几个 建筑 公司 来 投标 。 学校 希望 建筑 公司 的 报价 尽可能 低 ， 而且 还要 确保 质量 。 所以 学校 不能 只选 价格 最低 的 方案 ， 而是 要 挑选出 综合 评分 最优 的 方案 。 ,   要 做到 公正 客观 的 评分 ， 必须 确保 几件事 ： ,   首先 ， 学校 不能 让 内部 员工 来 评分 ， 因为 内部 员工 和 项目 有 直接 的 利益 关系 ， 员工 都 希望 自己 在 项目 中 获得 更 多 利益 ， 做 不到 评分 上 客观 独立 。 ,   所以 学校 只能 从 外部 请 专家 来 评标 ， 因为 外人 独立 于 学校 之外 ， 会 减少 直接 利益 所 产生 的 影响 。 ,   于是 学校 计划 邀请 3 个 专家 来 评审 ， 让 专家 对 建筑 公司 的 方案 和 报价 进行 综合 评分 。 ,   其次 ， 学校 在 挑选 专家 时 ， 要 尽可能 确保 这些 专家 之间 的 观点 也 必须 是 互相 独立 的 ， 不能 人云亦云 。 ,   假如 其中 1 人 是 另外 2 人 的 上级 ， 那 上级 说话 ， 下级 的 观点 就 倾向 于 和 上级 保持一致 ， 在 评分 时 无法 做到 独立 ， 这样 的 评分 是 有 偏差 的 。 花 了 3 个 专家 的 钱 ， 却成 了 1 个 专家 的 一言堂 。 专家 独立性 从 3 变成 了 1 ， 这 偏差 也 太大 了 。 ,   最后 ， 学校 还 必须 确保 ， 任何 一个 专家 都 没有 被 建筑 公司 收买 ， 是 独立 于 建筑 公司 ， 没有 利益输送 的 。 ,   如果 被 收买 了 ， 专家 就 会 修改 评分 ， 让 贿赂 的 商家 胜出 ， 这个 专家 的 数据 也 是 不 独立 客观 的 。 ,   ,   从 上面 的 这个 案例 里 ， 你 会 发现 独立 的 重要性 ， 一旦 出现 利益 关联 ， 独立性 就 会 降低 ， 数据 必然 会 出现 偏差 。 ,   类似 的 制度 设计 非常 的 广泛 ， 例如 陪审团 制度 ， 就 设计 了 大量 的 机制 来 保证 陪审团 成员 的 独立性 。 ,   < img   src = " https : / / pica . zhimg . com / 50 / v2 - f7edffa84fb78ce60db25379cfa304e3 _ 720w . jpg ? source = 1940ef5c "   data - size = " normal "   data - rawwidth = " 1940 "   data - rawheight = " 1092 "   data - default - watermark - src = " https : / / pic2 . zhimg . com / 50 / v2 - 2c507bd48ef5eb67f74b857a2fc4ea87 _ 720w . jpg ? source = 1940ef5c "   class = " origin _ image   zh - lightbox - thumb "   width = " 1940 "   data - original = " https : / / pic1 . zhimg . com / v2 - f7edffa84fb78ce60db25379cfa304e3 _ r . jpg ? source = 1940ef5c " / > 电影 《 十二 怒汉 》 剧照 ,   推荐 重温 一下 《 十二 怒汉 》 这部 经典 ， 看看 人们 的 偏见 （ Bias ） 是 如何 的 根深蒂固 ， 消除 偏见 是 如何 的 困难 。 ,   ,   几千年 来 ， 人类 为了 提高 独立性 ， 殚精竭虑 的 设计 了 各种 精巧 的 制度 ， 这些 制度 历久弥坚 ， 逐渐 成为 了 现代 社会 的 基石 。 ,   ,   在 统计 实践 中 人们 发现 ， 偏差 的 产生 ， 很多 时候 也 是因为 样本 数据 之间 出现 了 各种 隐含 的 关联 关系 ， 降低 了 数据 之间 的 独立性 。 ,   而 解决 的 策略 还 很 清晰 ， 就是 发现 其中 隐含 的 关联 关系 ， 然后 进行 校正 。 ,   ,   让 我们 再 回到 样本 方差 （ Sample   Variance ） 的 分母 （ n - 1 ） 上来 。 ,   你 既然 在 看 这个 问题 ， 那 就 已经 知道 了 方差 的 计算公式 ,   ,   需要 注意 的 是 这里 的 方差 其实 是 全体 的 方差 ， μ 是 全体 的 平均值 ， n 是 全体 变量 的 数量 ,   ,   例如 一家 啤酒厂 每天 生产 1 万瓶 啤酒 ， 我们 想 知道 这些 啤酒 的 质量 差异性 如何 ， 可以 打开 这 1 万瓶 啤酒 测量 ， 再 把 所有 测量 结果 代入 到 上面 的 公式 里求 方差 ， 在 计算 中 ， 没有 漏下 任何 一瓶 啤酒 的 数据 。 ,   你 也 发现 了 ， 这样 做 不仅 麻烦 了 ， 而且 成本 极高 。 ,   ,   更好 方法 是 对 出厂 的 啤酒 进行 随机 的 采样 ， 计算 这部分 样本 的 方差 。 ,   例如 ， 随机 的 从 产品 中 找出 100 瓶 ， 用 这 100 瓶来 估算 1 万瓶 啤酒 的 质量 差异 ， 注意 ， 除了 这 100 瓶 的 数据 ， 其他 9900 瓶 啤酒 数据 是 完全 未知 的 。 ,   样本 方差 它 是从 全体 数据 中 随机 取出 一小部分 所 做 的 计算 ， 用 这个 局部 的 100 瓶 啤酒 的 方差 去 估计 全体 1 万瓶 啤酒 的 方差 。 ,   ,   上面 这个 样本 方差 公式 ， 尽管 在 形式 上 和 全体 方差 的 公式 近似 ， 但是 内涵 上 发生 了 天翻地覆 的 变化 。 ,   ,   我们 来 比较 一下 ， 全体 方差 和 样本 方差 ： ,   全体 方差     是 一个 客观事实 （ Fact ） ， 是 对 所有 个体 数据 的 全体 所作 的 客观 描述 （ Describe ） 。 ,   而 样本 方差     更 像 一个 观点 （ Opinion ） ， 是 我们 根据 少量 抽样 个体 的 数据 ， 对 全体 所 作出 的 估算 （ Estimation ） ， 或者说 是 预测 。 ,   ,   既然 样本 方差     不是 一个 事实 ， 而是 一个 观点 ， 是 一种 估算 ， 为了 让 这个 估算 尽可能 的 接近 事实 ， 就 必须 注意 样本 不要 出现 偏差 （ Bias ） ， 否则 就 会 “ 垃圾 进 ， 垃圾 出 ” ， 得出 错误 的 估算 。 ,   例如 ,   我们 不能 只 对 某批 产品 取样 ， 某个 特定 时间 取样 ， 我们 的 随机取样 必须 尽可能 的 覆盖 所有 批次 ， 取样 要 有 充分 的 自由度 ， 足够 的 随机 。 另外 还要 注意 ， 避免 样本 里 的 变量 之间 存在 隐含 的 关联 关系 。 ,   ,   我们 来看 一个 例子 ,   假设 随机 抽出 的 样本 里 只有 两个 数   ,   如果 这 2 个数 是 独立 和 随机 抽取 的 ， 你 就 不能 从 x1 猜出 x2 ， 例如 我 告诉 你 x1 = 10 ， 请问 x2 等于 多少 ？ ,   你 根本 猜 不 出来 ， 因为 随机 抽取 让 x2 和 x1 之间 没有 关联 。 ,   ,   但是 ， 没想到 的 是 ， 因为 一个 数据 的 存在 ， 让 这个 随机取样 产生 了 一个 隐含 的 关联 关系 。 ,   这个 数 就是 计算 样本 方差   时 ， 需要 用到 的 样本 平均值   ， 他 的 引入 让 随机 抽取 的 独立性 和 自由度 减少 了 一点点 。 ,   因为 样本 平均值   引入 了 一些 信息 ， 让 x1 和 x2 之间 不再 是 相互 独立 的 关系 了 。 ,   ,   根据 平均值 公式 ,   ,   只要 知道 了 x1 和 ， 就 可以 计算 出 x2 的 值 。 ,   如果 x1 = 10 ， = 10 ， 那 x2 = 10 ,   ,   同样 ， 知道 了 x2 和 ， 就 可以 计算 出 x1 的 值 。 ,   如果 x2 = 10 ， = 11 ， 那 x1 = 12 ,   ,   也就是说 ， 出 问题 的 并 不是 x1 或者 x2 ， 这 两个 数 本来 好好 的 ， 互相 独立 的 。 出 问题 的 是 平均值 ， 他 引入 的 新 信息 ， 让 样本 数据 之间 的 独立性 减少 了 ， 关联性 增加 了 。 ,   或者 还 可以 说 ， 在 平均值 的 介入 下 ， x1 和 x2 的 自由度 降低 了 ， 原来 是 两个 独立 的 数 ， 现在 只有 一个 独立 了 ， 另 一个 则 不再 自由 ， 好像 有些 人云亦云 了 。 ,   ,   同样 的 ， 对于 更 多 的 样本量 ： ,   如果 样本 是 3 个数   ,   则 知道 了 x1 ， x2 ， 就 能 通过 ， 计算 出 x3 ， 独立性 或者说 自由度 ， 就 从 3 降到 了 2 。 ,   如果 样本 是 4 个数   ,   则 知道 了 x1 ， x2 ， x3 ， 就 能 通过 ， 计算 出 x4 ， 独立性 或者说 自由度 ， 就 从 4 降到 了 3 。 ,   … … ,   如果 样本 是 n 个数   ,   则 知道 了 x1 ， x2 , ... ,     ， 就 能 通过 ， 计算 出     ， 独立性 或者说 自由度 ， 就 从 n 降到 了 n - 1 。 ,   平均值 让 样本 的 独立性 或 自由度 减少 了 1 ， 导致 了 样本 出现 了 偏差 。 ,   这 就是 为什么 样本 方差 的 分母 不是 n ， 也 不是 n - 2 或 n - 3 ， 而是 n - 1 的 原因 。 ,   ,   自由度 变小 会 对 样本 方差 产生 什么 影响 呢 ？ ,   这 意味着 ， 样本 方差 会 变小 。 ,   我们 知道 ， 方差 是 通过 计算 样本 和 平均值 之间 的 距离 ， 来 描述 样本 的 分散 程度 ， 数据 之间 差异 越大 ， 方差 越大 ， 数据 之间 越是 趋同 ， 方差 越小 。 ,   还是 用 专家 评分 的 案例 来 解释 ： ,   如果 专家组 中 ， 所有人 都 独立 ， 每个 人 的 评分 会 出现 较大 的 差异性 。 ,   但 如果 专家组 中有 个 领导 ， 他 自己 没有 任何 主见 ， 只是 在 看 完 大家 的 评分 之后 ， 取个 折中 的 评分 ， 是 个 老好人 型 的 领导 。 ,   请 注意 ， 这个 领导 没有 贡献 任何 新 观点 ， 他 的 观点 不 独立 ， 只是 重复 了 别人 的 观点 ， 但 这个 重复 数据 污染 了 整体 数据 的 独立性 ， 让 原本 差异性 较大 数据 ， 因为 折中 数据 的 出现 ， 减少 了 差异 ， 或者说 ， 出现 了 一些 趋同 效应 ， 这 就 产生 了 偏差 。 ,   ,   回到 样本 方差     上 ， 因为 样本 平均值     就是 根据 样本 来 计算 的 ， 样本 平均值     成 了 那个 贡献 重复 数据 的 领导 ， 让 原来 独立 的 、 随机 的 、 没有 偏差 的 样本 数据 ， 在 计算 加工过程 中 引入 了 偏差 ， 减少 了 数据 之间 的 差异性 ， 这种 趋同 效应 让 样本 方差     变小 。 ,   也就是说 ， 数据 取样 没 问题 ， 是 无偏 的 。 但是 在 后来 的 方差 计算 中 ， 均值 的 引入 ， 让 差异性 减少 ， 本来 无偏 的 数据 出现 了 偏差 。 样本 方差 会 一直 小于 总体 方差 ， 这是 一个 有 偏 样本 方差 。 ,   ,   上面 是 有 偏差 的 样本 方差 公式 ， 是 没有 经过 校正 的 。 ,   普鲁士 天文学家 贝塞尔 （ Bessel ） 在 对 海量 的 观测 数据 做 计算 时 ， 也 注意 到 了 这个 偏差 。 ,   这个 偏差 的 特点 是 ： ,   在 样本量 小 的 时候 偏差 影响 比较 明显 ， 样本 方差 比 全体 方差 偏小 。 但是 当 样本量 增大 时 ， 偏差 逐渐 减少 ， 直到 影响 可以 忽略不计 。 ,   ,   既然 样本 方差 变小 了 ， 那 干脆 让 分母 变小 ， 增大 样本 方差 就行了 。 ,   贝塞尔 给出 了 修正 方法 ， 即 把 样本 方差 公式 的 分母 修正 为 n - 1 ， 所以 这个 修正 被 后人 称为 贝塞尔 校正 。 ,   ,   " 具体 的 公式 推导 过程 ， 可以 看 Emory   University 的 这篇 关于 Bessels   Correction 推导 的 文章   [ 8 ] " ,   < img   src = " https : / / pic2 . zhimg . com / 50 / v2 - cf2e4b3a33f167ccfba6767a16797a00 _ 720w . jpg ? source = 1940ef5c "   data - size = " normal "   data - rawwidth = " 900 "   data - rawheight = " 761 "   data - default - watermark - src = " https : / / pic1 . zhimg . com / 50 / v2 - 1b95680ed20b4fa7c0d4c83c8363913d _ 720w . jpg ? source = 1940ef5c "   class = " origin _ image   zh - lightbox - thumb "   width = " 900 "   data - original = " https : / / pic1 . zhimg . com / v2 - cf2e4b3a33f167ccfba6767a16797a00 _ r . jpg ? source = 1940ef5c " / > 德国 天文学家 和 数学家 弗里德里希 · 威廉 · 贝塞尔 ,   图片 出处 ： https : / / zh . wikipedia . org / wiki / % E5% BC% 97% E9% 87% 8C% E5% BE% B7% E9% 87% 8C% E5% B8% 8C% C2% B7% E5% A8% 81% E5% BB% 89% C2% B7% E8% B4% 9D% E5% A1% 9E% E5% B0% 94 ,   样本 方差 公式 里 的 分母 n - 1 ， 就是 这么 来 的 ， 那个 减去 的 1 ， 就是 用来 校正 所 带来 的 偏差 ， 他 不 代表 某 一个 样本 ， 而是 对 自由度 的 补偿 ， 让 缩小 的 样本 方差 重新 变 大 一点 。 ,   ,   样本 方差 偏小 是不是 采样 出现 问题 ？ 因为 越 接近 平均值 ， 就 越 容易 被 采样 ？ ,   从 直觉 上 好像 是 这样 的 ， 比如 下面 的 这个 鱼类 长度 的 分布 ， 数据 聚集 在 平均值 106 （ 蓝线 ） 附近 ， 如果 采样 ， 在 平均值 周围 的确 有 更 大 的 概率 被 采样 到 。 ,   < img   src = " https : / / pic1 . zhimg . com / 50 / v2 - 9581c8cc2bcd428950333276d9fbcc44 _ 720w . jpg ? source = 1940ef5c "   data - caption = " "   data - size = " normal "   data - rawwidth = " 1572 "   data - rawheight = " 718 "   data - default - watermark - src = " https : / / pica . zhimg . com / 50 / v2 - 7442749281630bf7b5c7a1c177d4fd0c _ 720w . jpg ? source = 1940ef5c "   class = " origin _ image   zh - lightbox - thumb "   width = " 1572 "   data - original = " https : / / pic3 . zhimg . com / v2 - 9581c8cc2bcd428950333276d9fbcc44 _ r . jpg ? source = 1940ef5c " / > ,   但是 ， 直觉 是 靠不住 的 。 上面 的 分布 只是 一种 ， 还有 很多 的 分布 ， 其 数据 不 在 平均值 附近 ， 而是 分散 在 四处 。 ,   例如 ， 下面 这个 西班牙 流感 死亡 年龄 的 分布 ,   < img   src = " https : / / pic3 . zhimg . com / 50 / v2 - 90a964739c241cf6b35b91fa5700a625 _ 720w . jpg ? source = 1940ef5c "   data - caption = " "   data - size = " normal "   data - rawwidth = " 1590 "   data - rawheight = " 662 "   data - default - watermark - src = " https : / / pica . zhimg . com / 50 / v2 - 16c242b146f47f366cc2e51ed85813b9 _ 720w . jpg ? source = 1940ef5c "   class = " origin _ image   zh - lightbox - thumb "   width = " 1590 "   data - original = " https : / / pic1 . zhimg . com / v2 - 90a964739c241cf6b35b91fa5700a625 _ r . jpg ? source = 1940ef5c " / > ,   数据 并 没有 聚集 在 平均值 43 附近 ， 如果 取样 ， 就 会 发现 样本 更大 的 概率 是 远离 平均值 ， 而 不是 在 平均值 附近 。 ,   所以 样本 方差 出现 偏小 的 原因 ， 并 不是 因为 平均值 附近 被 采样 到 的 概率 更大 ， 这 只 在 部分 情况 下 成立 ， 在 很多 情况 下 并 不 成立 。 ,   样本 方差 出现 偏差 的 原因 和 采样 无关 ， 也 和 平均值 附近 更 容易 被 采样 无关 ， 因为 在 很多 情况 下 ， 远离 平均值 的 数据 更 容易 被 采样 到 ， 这 无法解释 样本 方差 为什么 会 比 全体 方差 小 。 ,   更好 的 解释 是 ， 计算 过程 中 引入 样本 平均值 ， 降低 了 样本 的 自由度 ， 减少 了 数据 的 差异性 。 ,   ,   所以 直觉 也 是 靠不住 的 ， 事实上 ， 有太多 的 偏差 和 偏见 （ Bias ） 是 由 直觉 贡献 的 。 ,   ,   结论 ,   " 样本 标准差 的 分母 写成 n - 1 ， 是 为了 对 数据 进行 校正 ， 这 叫 贝塞尔 校正 （ Bessels   Correction ） 。 统计 经常 用 各种 方法 来 消除 掉 干扰 数据 的 影响 ， 例如 比尔盖茨 和 去掉 最高 / 低分 的 这 两个 例子 。 样本 数据 之间 也 经常 会 出现 各种 隐含 的 关联 关系 ， 降低 了 数据 之间 的 独立性 或 自由度 （ Degrees   of   freedom ） ， 这会 让 样本 更 聚集 ， 让 样本偏差 变小 。 样本 方差 公式 里 的 分母 n - 1 ， 就是 校正 样本 平均值 所 减少 的 自由度 ， 样本 数据 本身 没有 偏差 ， 是 计算 过程 中 引入 的 新 信息 （ 样本均值 ） ， 让 计算结果 出现 了 偏差 。 " ,   ,   推荐 阅读 ,   [ 1 ] https : / / en . wikipedia . org / wiki / Bessel% 27s _ correction ,   [ 2 ] https : / / heap . io / blog / data - stories / garbage - in - garbage - out - how - anomalies - can - wreck - your - data ,   [ 3 ] https : / / zh . wikipedia . org / wiki / % E8% BB% BC% E4% BA% 8B% E8% AD% 89% E6% 93% 9A ,   [ 4 ] https : / / zh . wikipedia . org / wiki / % E4% BB% A5% E5% 81% 8F% E6% A6% 82% E5% 85% A8 ,   [ 5 ] https : / / zh . wikipedia . org / wiki / 1948% E5% B9% B4% E7% BE% 8E% E5% 9B% BD% E6% 80% BB% E7% BB% 9F% E9% 80% 89% E4% B8% BE ,   [ 6 ] http : / / www . todayonhistory . com / lishi / 201705 / 62790 . html [ 7 ] https : / / zh . wikipedia . org / wiki / % E5% 81% 8F% E5% B7% AE% E6% A8% A3% E6% 9C% AC ,   [ 8 ] http : / / math . oxford . emory . edu / site / math117 / besselCorrection / ]