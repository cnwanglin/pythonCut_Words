[ 以前 天天 跟 导师 探讨 AI 的 未来 发展 之 路 ， 我 就 来 写 两笔 。 我 目前 来看 ， 最急 需要 解决 的 问题 如下 ： ,   ,   1 . RL 的 样本 复杂度 问题 。 从 13 年 的 Atari ， 到 16 年 的 AlphaGo ， 到 今年 的 Dota   5v5 和 星际争霸 ， 每个 游戏 都 经历 了 N 多个 （ 可能 如果 复原 到 人类 时间 是 几百年 + ） 样本 ， 才 可以 学到 一个 好 的 policy 。 如果 通用 智能 出来 ， 那么 一定 不是 在 游戏 里 ， 而是 在 现实 世界 中 。 现实 世界 中 没有 办法 给 你 这么 多次 尝试 的 机会   --   生命诚可贵 ， 人 只活 一次 。 不管 是 imitation   learning ， meta   learning 还是 最近 OpenAI 出 的 ADR ， 距离 解决 这个 问题 都 还是 有 距离 。 甚至 我们 可能 要 挑战 增强 学习 RL 这个 学习 框架 本身 。 ,   " 2 . 受 Yann 的 影响 太深   --   无 监督 学习 。 我 是 比较 相信 人们 可以 从 观看 世界 中学 到 东西 的 。 但是 怎么 学 ， 学到 的 是 什么 ， 如何 eval ， 目前 我们 甚至 都 没有 定义 清楚 无 监督 学习 到底 是 什么 （ 我 的 博士 毕业论文 就 写 的 这个 主题 ， 真是 惭愧 得 很 ） 。 宏观 上 是 这样 ， 微观 上 更是 ， 我 做 GAN 的 时候 15 年 开始 ， 如今 快 20 年 了 ， 我 依然 没有 看到 一个 满意 的 权衡 图片 生成 质量 的 方法 （ 堆人 来看 都行 啊 ！ Youre   welcome ,   Amazon ） 。 再说 大 一点 ， GAN 给 我们 带来 一种 approximate   数据分布 的 生成 机制 ， 我们 如何 将 这个 问题 formulate 到 无 监督 学习 里面 ？ " ,   3 . 层级 化 学习 。 “ 我要 去 楼下 吃 一碗 拉面 ” 。 这个 问题 是 个 RL 问题 吗 ？ 当然 可以 这么 做 ， 你 成功 走到 了 面馆 ， 我 给你个 reward ， 否则 没有 。 但 实际上 不是 这样 的 ， 这里 的 policy 有 非常 结构化 的 层级 性 。 第一个 分解 动作 是 ， 我要 先 走出 我 的 屋子 ， 然后 走 到 电梯 ， 下楼 ， 出楼 ， 之后 走 到 面馆 。 那么 每个 动作 都 可以 再细 ：   比如说 我 怎么 走出 屋子 ？ 我 首先 是 两 脚蹬 地 ， 起身 ， 站 直 ， 收 臀 ， 然后 转身 ， 走向 门 。 我们 有 这样 的 问题 定义 吗 ？ ,   4 . 图像 分类 问题 需要 被 重新 评估 A .   当 你 看到 一个 东西 是 苹果 的 时候 ， 你 是 如何 做 的 判断 ？ 你 不是 某个 角度 （ 不管 是 2D 还是 3D ） 来 一张 图 ， 之后 就 能 判断 了 。 你 的 判断 方式 是 ， 你 走 过去 ， 四周 看一看 ， 甚至 摸 一摸 ， 然后 做出 一个 判断 。 大家 都 说 多 模态 多 模态 ， 我们 现在 CV 依然 没有 走出 单 模态 的 阴影 。 ,   5 . 图像 分类 问题 需要 被 重新 评估 B .   你 看到 一个 桌子 ， 它 确实 是 个 桌子 ， 这 没错 。 但是 我 要是 坐上去 呢 ？ 你 的 分类 应该 把 它 当成 一个 椅子 ， 而 不是 桌子 。 我们 的 图像 分类 算法 如果 被 看成 policy 的话 ， 这个 policy 的 state 太 单一 了 （ 就是 一张 图 ） ， 但是 其实 它 的 state 需要 被 更加 丰富化 才 可以 。 可 控制 的 文本 生成 。 大家 都 觉得 好 热闹 啊 这 一年 多 ， ELMO ,   BERT ,   XLNET ,   GPT - 2 ,   Roberta ,   T5 等等 。 GPT - 2 可以 做 的 文本 生成 太 厉害 了 ， 那 句子 真实 到 爆 。 但是 ， 你 怎么 控制 它 呢 ？ 比如说 我 想 生成 个 新闻稿 ， 我 要求 每个 字 每句话 都 跟 主题 息息相关 ， 责任编辑 的 名字 不能 瞎闹 ， 这个 问题 到 今天 都 没有 解决方案 哦 。 说到底 ， 我们 不 知道 一个 RNN 语言 模型 是 怎么 工作 的 ， 尤其 是 有 condition 的 时候 ， 什么 时候 是 根据 语言 本身 的 流利 度 生成 ( unconditional )     什么 时候 是 根据 condition 来 生成 ， 目前 我们 没 办法 开发 一个 合适 gating 方式 来 区分 。 NLG 想 真正 落地 ， 这个 问题 不 解决 的话 ， 没有 一点 希望 （ Forgive   me 创业者 们 ） 。 ,   6 . 符号 主义 ？ Gary   Marcus 一直 在 死 咬 着 这个 点 。 我 的 观点 目前 比较 中立 ： 我们 或许 应该 融合 符号 主义 ， 而 不是 完全 ditch 掉 它 。 最 简单 的 ， 我 很 欣喜 可以 看到 有些 工作 是 真正 得 把 知识 图谱 或者 语法 信息 用到 NLP 问题 上面 了 ， 而且 效果 确实 有些 提升 。 但 同时 ， 我们 真的 需要 知识 图谱 吗 ？ BERT 训练 的 方式 能 不能 作为 一个 知识 图谱 。 同学 们 ， 掏出 你 的 BERT 模型 ， 输入 一句   The   CEO   of   Baidu   is   < mask > 。 看看 它 给 你 返回 什么 ？ 我 的 意思 是 ： 三元组 ， 四元组 这样 的 简单 知识 图谱 的 定义 已经 不 适用 了 。 混 了 工业界 一段时间 ， 我 看到 的 真实世界 中 的 数据 维度 太太 太太 太多 了 ， 三 或者 四 都 远远 不足 ， 我们 要 的 是 个 Variable - number 元祖 。 或许 BERT 给出 了 一条 新路 。 ,   ,   最后 ， 大家 请 加油 吧 。 AI 的 研究 上面 真的 有太多 痛点 问题 需要 被 解决 。 上面 任何 一个 问题 解决 我 都 认为 是 伟大 的 ， 都 会 避免 下 一个 寒冬 。 请 不要 再 死死 盯住 一个 benchmark 不放去 刷分 了 呀 年轻 人们 ！ 要么 落地 一个 场景 ， 要么 解决 一个 问题 。 Research 最 有趣 的 就是 把 一个 问题 从头到尾 定义 得 明明白白 ， 颇 见 功力 。 ,   ,   也 推荐 下 我 的 知识 星球 吧 ， 时不时 会 写点 干货 ~   ( 这个 是 我 ：   https : / / cs . nyu . edu / ~ jakezhao / research . html ） ,   < img   src = " https : / / pica . zhimg . com / 50 / v2 - 60c0705b5feef21f59ef50a3d4ff2706 _ 720w . jpg ? source = 1940ef5c "   data - caption = " "   data - size = " normal "   data - rawwidth = " 690 "   data - rawheight = " 930 "   data - default - watermark - src = " https : / / pic3 . zhimg . com / 50 / v2 - dc1a73a5244820b4b69e211bf8d2a411 _ 720w . jpg ? source = 1940ef5c "   class = " origin _ image   zh - lightbox - thumb "   width = " 690 "   data - original = " https : / / pic2 . zhimg . com / v2 - 60c0705b5feef21f59ef50a3d4ff2706 _ r . jpg ? source = 1940ef5c " / > ]